{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db244738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adce3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PORTER STEMMER EVALUATION\n",
    "def load_gold_standard(gold_folder=\"BING preprocessed\"):\n",
    "    gold_data = {}\n",
    "    for filename in os.listdir(gold_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(gold_folder, filename), 'r', encoding='utf-8') as f:\n",
    "                content = f.read().split()\n",
    "                gold_data[filename] = content\n",
    "    return gold_data\n",
    "\n",
    "def load_stemmed_results(result_folder=\"english stemmed output\"):\n",
    "    stemmed_data = {}\n",
    "    for filename in os.listdir(result_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(result_folder, filename), 'r', encoding='utf-8') as f:\n",
    "                content = f.read().split()\n",
    "                stemmed_data[filename] = content\n",
    "    return stemmed_data\n",
    "\n",
    "def evaluate_stemming_performance(gold_folder, result_folder):\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    all_words = []\n",
    "    all_stemmed = []\n",
    "    stem_map = defaultdict(set)\n",
    "    \n",
    "    # Loop through all files in the gold folder\n",
    "    for filename in os.listdir(gold_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(gold_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                tokens = word_tokenize(text.lower())\n",
    "                all_words.extend(tokens)\n",
    "                stemmed = [stemmer.stem(w) for w in tokens]\n",
    "                all_stemmed.extend(stemmed)\n",
    "\n",
    "                # Create stem -> original words mapping\n",
    "                for orig, stem in zip(tokens, stemmed):\n",
    "                    stem_map[stem].add(orig)\n",
    "    \n",
    "    # Calculate MWC (Mean Word Conflation)\n",
    "    total_words = len(all_words)\n",
    "    unique_stems = len(set(all_stemmed))\n",
    "    MWC = total_words / unique_stems if unique_stems != 0 else 0\n",
    "    \n",
    "    # Calculate Overstemming Index\n",
    "    overstem_pairs = 0\n",
    "    for stem, originals in stem_map.items():\n",
    "        if len(originals) > 1:\n",
    "            overstem_pairs += len(originals) - 1  # How many words are excessively merged\n",
    "    \n",
    "    # Calculate Understemming Index\n",
    "    # Find words with the same prefix but different stems\n",
    "    understem_pairs = 0\n",
    "    prefix_map = defaultdict(set)\n",
    "    for word, stem in zip(all_words, all_stemmed):\n",
    "        if len(word) >= 4:  # Make sure word is long enough for prefix\n",
    "            prefix = word[:4]  # Take first 4 characters as prefix\n",
    "            prefix_map[prefix].add(stem)\n",
    "    \n",
    "    for stems in prefix_map.values():\n",
    "        if len(stems) > 1:\n",
    "            understem_pairs += len(stems) - 1\n",
    "    \n",
    "    # Normalize OI and UI\n",
    "    normalized_OI = overstem_pairs / unique_stems if unique_stems != 0 else 0\n",
    "    normalized_UI = understem_pairs / unique_stems if unique_stems != 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Total_Words': total_words,\n",
    "        'Unique_Stems': unique_stems,  # Still keeping in return value for internal use if needed\n",
    "        'Mean_Word_Conflation': MWC,\n",
    "        'Overstemming_Index': normalized_OI,\n",
    "        'Understemming_Index': normalized_UI\n",
    "    }\n",
    "\n",
    "def generate_error_report(gold_folder, result_folder, output_file=\"error_report_porter.txt\"):\n",
    "    gold_standard = load_gold_standard(gold_folder)\n",
    "    stemmed_results = load_stemmed_results(result_folder)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as report:\n",
    "        report.write(\"ERROR ANALYSIS REPORT\\n\")\n",
    "        report.write(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        error_types = defaultdict(int)\n",
    "        word_errors = defaultdict(int)\n",
    "        \n",
    "        for filename in gold_standard:\n",
    "            if filename not in stemmed_results:\n",
    "                continue\n",
    "                \n",
    "            gold_tokens = gold_standard[filename]\n",
    "            stemmed_tokens = stemmed_results[filename]\n",
    "            \n",
    "            report.write(f\"\\nFile: {filename}\\n\")\n",
    "            report.write(\"-\"*50 + \"\\n\")\n",
    "            \n",
    "            for i, (gold_word, stemmed_word) in enumerate(zip(gold_tokens, stemmed_tokens)):\n",
    "                if stemmed_word != gold_word:\n",
    "                    error_type = \"UNDER\" if len(stemmed_word) > len(gold_word) else \"OVER\"\n",
    "                    error_types[error_type] += 1\n",
    "                    word_errors[f\"{gold_word}→{stemmed_word}\"] += 1\n",
    "                    \n",
    "                    report.write(f\"Token {i+1}: {gold_word} → {stemmed_word} ({error_type})\\n\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        report.write(\"\\n\\nSUMMARY STATISTICS\\n\")\n",
    "        report.write(\"=\"*50 + \"\\n\")\n",
    "        report.write(f\"Total Errors: {sum(error_types.values())}\\n\")\n",
    "        report.write(f\"Understemming Errors: {error_types.get('UNDER', 0)}\\n\")\n",
    "        report.write(f\"Overstemming Errors: {error_types.get('OVER', 0)}\\n\")\n",
    "        \n",
    "        # Most common errors\n",
    "        report.write(\"\\nTOP 10 MOST COMMON ERRORS\\n\")\n",
    "        for error, count in sorted(word_errors.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            report.write(f\"{error}: {count} occurrences\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba490eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PORTER STEMMER EVALUATION RESULTS:\n",
      "==================================================\n",
      "Total Tokens Analyzed: 33417\n",
      "Mean Word Conflation (MWC): 7.12\n",
      "Overstemming Index (OI): 0.3778\n",
      "Understemming Index (UI): 0.3708\n",
      "\n",
      "Error report generated: error_report_porter.txt\n"
     ]
    }
   ],
   "source": [
    "##PORTER STEMMER\n",
    "if __name__ == \"__main__\":\n",
    "    gold_folder = \"BING preprocessed\"  # Folder with gold standard texts\n",
    "    result_folder = \"english stemmed output\"  # Stemming output folder\n",
    "    \n",
    "    results = evaluate_stemming_performance(gold_folder, result_folder)\n",
    "    \n",
    "    print(\"\\nPORTER STEMMER EVALUATION RESULTS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Tokens Analyzed: {results['Total_Words']}\")  # Changed from \"Total Words Analyzed\" to \"Total Tokens Analyzed\"\n",
    "    print(f\"Mean Word Conflation (MWC): {results['Mean_Word_Conflation']:.2f}\")\n",
    "    print(f\"Overstemming Index (OI): {results['Overstemming_Index']:.4f}\")\n",
    "    print(f\"Understemming Index (UI): {results['Understemming_Index']:.4f}\")\n",
    "    \n",
    "    # Generate detailed error report\n",
    "    generate_error_report(gold_folder, result_folder)\n",
    "    print(\"\\nError report generated: error_report_porter.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591eb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ECS STEMMER EVALUATION\n",
    "def load_gold_standard(gold_folder=\"BIND preprocessed\"):\n",
    "    gold_data = {}\n",
    "    for filename in os.listdir(gold_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(gold_folder, filename), 'r', encoding='utf-8') as f:\n",
    "                content = f.read().split()\n",
    "                gold_data[filename] = content\n",
    "    return gold_data\n",
    "\n",
    "def load_stemmed_results(result_folder=\"hasil_stemming\"):\n",
    "    stemmed_data = {}\n",
    "    for filename in os.listdir(result_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(result_folder, filename), 'r', encoding='utf-8') as f:\n",
    "                content = f.read().split()\n",
    "                stemmed_data[filename] = content\n",
    "    return stemmed_data\n",
    "\n",
    "def evaluate_stemming_performance(gold_folder, result_folder):\n",
    "    gold_standard = load_gold_standard(gold_folder)\n",
    "    stemmed_results = load_stemmed_results(result_folder)\n",
    "    \n",
    "    total_tokens = 0\n",
    "    understemming = 0\n",
    "    overstemming = 0\n",
    "    correct = 0\n",
    "    consistency_groups = defaultdict(set)\n",
    "    \n",
    "    for filename in gold_standard:\n",
    "        if filename not in stemmed_results:\n",
    "            continue\n",
    "            \n",
    "        gold_tokens = gold_standard[filename]\n",
    "        stemmed_tokens = stemmed_results[filename]\n",
    "        \n",
    "        for gold_word, stemmed_word in zip(gold_tokens, stemmed_tokens):\n",
    "            total_tokens += 1\n",
    "            if stemmed_word == gold_word:\n",
    "                correct += 1\n",
    "            elif len(stemmed_word) > len(gold_word):\n",
    "                understemming += 1\n",
    "            else:\n",
    "                overstemming += 1\n",
    "                \n",
    "            consistency_groups[stemmed_word].add(gold_word)\n",
    "    \n",
    "    # Hitung metrik evaluasi\n",
    "    UI = understemming / total_tokens\n",
    "    OI = overstemming / total_tokens\n",
    "    \n",
    "    # Hitung MWC (Mean Word Conflation)\n",
    "    conflation_sum = 0\n",
    "    for stem, words in consistency_groups.items():\n",
    "        conflation_sum += len(words)\n",
    "    \n",
    "    MWC = conflation_sum / len(consistency_groups) if consistency_groups else 0\n",
    "    \n",
    "    return {\n",
    "        'Total_Tokens': total_tokens,\n",
    "        'Understemming_Index': UI,\n",
    "        'Overstemming_Index': OI,\n",
    "        'Mean_Word_Conflation': MWC\n",
    "    }\n",
    "\n",
    "def generate_error_report(gold_folder, result_folder, output_file=\"error_report_ecs.txt\"):\n",
    "    gold_standard = load_gold_standard(gold_folder)\n",
    "    stemmed_results = load_stemmed_results(result_folder)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as report:\n",
    "        report.write(\"ERROR ANALYSIS REPORT\\n\")\n",
    "        report.write(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        error_types = defaultdict(int)\n",
    "        word_errors = defaultdict(int)\n",
    "        \n",
    "        for filename in gold_standard:\n",
    "            if filename not in stemmed_results:\n",
    "                continue\n",
    "                \n",
    "            gold_tokens = gold_standard[filename]\n",
    "            stemmed_tokens = stemmed_results[filename]\n",
    "            \n",
    "            report.write(f\"\\nFile: {filename}\\n\")\n",
    "            report.write(\"-\"*50 + \"\\n\")\n",
    "            \n",
    "            for i, (gold_word, stemmed_word) in enumerate(zip(gold_tokens, stemmed_tokens)):\n",
    "                if stemmed_word != gold_word:\n",
    "                    error_type = \"UNDER\" if len(stemmed_word) > len(gold_word) else \"OVER\"\n",
    "                    error_types[error_type] += 1\n",
    "                    word_errors[f\"{gold_word}→{stemmed_word}\"] += 1\n",
    "                    \n",
    "                    report.write(f\"Token {i+1}: {gold_word} → {stemmed_word} ({error_type})\\n\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        report.write(\"\\n\\nSUMMARY STATISTICS\\n\")\n",
    "        report.write(\"=\"*50 + \"\\n\")\n",
    "        report.write(f\"Total Errors: {sum(error_types.values())}\\n\")\n",
    "        report.write(f\"Understemming Errors: {error_types.get('UNDER', 0)}\\n\")\n",
    "        report.write(f\"Overstemming Errors: {error_types.get('OVER', 0)}\\n\")\n",
    "        \n",
    "        # Most common errors\n",
    "        report.write(\"\\nTOP 10 MOST COMMON ERRORS\\n\")\n",
    "        for error, count in sorted(word_errors.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            report.write(f\"{error}: {count} occurrences\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77155095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ECS STEMMER EVALUATION RESULTS:\n",
      "==================================================\n",
      "Total Tokens Analyzed: 22582\n",
      "Understemming Index (UI): 0.0013\n",
      "Overstemming Index (OI): 0.2711\n",
      "Mean Word Conflation (MWC): 1.4270\n",
      "\n",
      "Error report generated: error_report_ecs.txt\n"
     ]
    }
   ],
   "source": [
    "##ECS STEMMER EVALUATION\n",
    "if __name__ == \"__main__\":\n",
    "    gold_folder = \"BIND preprocessed\"  # Folder berisi file teks dengan stem benar\n",
    "    result_folder = \"hasil_stemming\"  # Folder output stemming\n",
    "    \n",
    "    results = evaluate_stemming_performance(gold_folder, result_folder)\n",
    "    \n",
    "    print(\"\\nECS STEMMER EVALUATION RESULTS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Tokens Analyzed: {results['Total_Tokens']}\")\n",
    "    print(f\"Understemming Index (UI): {results['Understemming_Index']:.4f}\")\n",
    "    print(f\"Overstemming Index (OI): {results['Overstemming_Index']:.4f}\")\n",
    "    print(f\"Mean Word Conflation (MWC): {results['Mean_Word_Conflation']:.4f}\")\n",
    "    \n",
    "    # Generate detailed error report\n",
    "    generate_error_report(gold_folder, result_folder)\n",
    "    print(\"\\nError report generated: error_report_ecs.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
